{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts\n",
    "\n",
    "This notebook will reproduce an excellent work of Google on multi task learning, [**Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts**](https://dl.acm.org/doi/pdf/10.1145/3219819.3220007). \n",
    "The paper proposed a multi-task learning approach named Multi-gate Mixture-of-Experts(MMoE) which explicitly learns\n",
    "to model task relationships from data, and studied the tradeoffs between task-specic objectives and inter-task relationships. The MMoE model is adapted from the Mixture-of-Experts (MoE) structure to multi-task learning by sharing the expert submodels across all tasks, while also having a gating network trained to optimize each task.\n",
    "\n",
    "Our work in the notebook can be summarized as follows:\n",
    "- implements the MoE, MMoE, shared-bottom model under the two regression task setting\n",
    "- compare the performance of MMoE with baselines at different levels of task relatedness\n",
    "\n",
    "The dataset used here is synthesized according to the paper. The work coverd here is corresponding to the following sections of the paper: \n",
    "- Section 3. PRELIMINARY\n",
    "- Section 5. MMOE ON SYNTHETIC DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from paperlab.core import Config, ExpRunner\n",
    "from paperlab.zoo import mmoe\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {\n",
    "    \"train_data_size\": 1000000,\n",
    "    \"dev_data_size\": 5000,\n",
    "    \"num_sin_params\": 4,\n",
    "    \"model\": \"moe\",\n",
    "    \"model_arch.dim_in\": 100,\n",
    "    \"model_arch.dim_hidden_bottom\": 16,\n",
    "    \"model_arch.dim_hidden_tower\": 8,\n",
    "    \"model_arch.num_expert\": 8,\n",
    "    \"model_arch.num_task\": 2,\n",
    "    \"num_epoch\": 50,\n",
    "    \"batch_size\": 40,\n",
    "    \"lr\": 1e-4,\n",
    "    \"num_process\": 4,\n",
    "    \"task_corr\": 0.1,\n",
    "    \"validate_freq\": 100000\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance of the Shared-Bottom model on synthetic data with different task correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_result(exp_runner):\n",
    "    df_source = []\n",
    "    for result in exp_runner.exp_results:\n",
    "        df_source.append(dict(result))\n",
    "    # process mean value from each single run\n",
    "    return pd.DataFrame(df_source).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_data_size': 1000000, 'dev_data_size': 5000, 'num_sin_params': 4, 'model': 'shared_bottom', 'model_arch': {'dim_in': 100, 'dim_hidden_bottom': 113, 'dim_hidden_tower': 8, 'num_expert': 8, 'num_task': 2}, 'num_epoch': 50, 'batch_size': 40, 'lr': 0.0001, 'num_process': 4, 'task_corr': 0.1, 'validate_freq': 100000}\n"
     ]
    }
   ],
   "source": [
    "config = Config(**conf)\n",
    "config.model = 'shared_bottom'\n",
    "# hard set the dimensionality of the bottom net to reach a comparable parameter number with MMoE and MoE\n",
    "config.model_arch.dim_hidden_bottom = 113\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment starts ...\n",
      "repeat running 8 times, random seeds are [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "config:\n",
      "\t config = {'train_data_size': 1000000, 'dev_data_size': 5000, 'num_sin_params': 4, 'model': 'shared_bottom', 'model_arch': {'dim_in': 100, 'dim_hidden_bottom': 113, 'dim_hidden_tower': 8, 'num_expert': 8, 'num_task': 2}, 'num_epoch': 50, 'batch_size': 40, 'lr': 0.0001, 'num_process': 4, 'task_corr': 0.5, 'validate_freq': 100000}\n",
      "Cannot get the env variable of GPU_STATUS_FILE, no data report to scheduler. This is not an error. It is because the scheduler of the cluster did not enable this feature.\n",
      "Cannot get the env variable of GPU_STATUS_FILE, no data report to scheduler. This is not an error. It is because the scheduler of the cluster did not enable this feature.\n",
      "Cannot get the env variable of GPU_STATUS_FILE, no data report to scheduler. This is not an error. It is because the scheduler of the cluster did not enable this feature.\n",
      "Cannot get the env variable of GPU_STATUS_FILE, no data report to scheduler. This is not an error. It is because the scheduler of the cluster did not enable this feature.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shared_bottom_stats = {}\n",
    "\n",
    "for task_corr in [0.5, 0.9, 1.0]:\n",
    "    config.task_corr = task_corr  # change the task correlation\n",
    "    \n",
    "    # set up experiment runner, repeat running 10 times under different random seed\n",
    "    runner = ExpRunner(mmoe.exp, {'config': config}, repeat_num=8)\n",
    "    runner.run_mp()  # run exp under multi-processing setting\n",
    "    \n",
    "    series = process_result(runner)\n",
    "    shared_bottom_stats[task_corr] = series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show the validation loss of the shared-bottom model under different task-correlation to validate the hypthesis that the task-correlation affects the performance of multi-task learning model.\n",
    "\n",
    "Higer the task-correlation is, better the multi-task learning model perform, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task_corr in shared_bottom_stats:\n",
    "    plt.plot(shared_bottom_stats[task_corr], label=f'task_corr={task_corr}')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "# plt.ylim(0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on MMoE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(**conf)\n",
    "config.model = 'mmoe'\n",
    "config.model_arch.dim_hidden_bottom = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmoe_stats = {}\n",
    "\n",
    "for task_corr in [0.5, 0.9, 1.0]:\n",
    "    config.task_corr = task_corr\n",
    "    runner = ExpRunner(mmoe.exp, {'config': config}, repeat_num=8)\n",
    "    runner.run_mp()\n",
    "    series = process_result(runner)\n",
    "    mmoe_stats[task_corr] = series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on MoE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(**conf)\n",
    "config.model = 'moe'\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moe_stats = {}\n",
    "\n",
    "for task_corr in [0.5, 0.9, 1.0]:\n",
    "    config.task_corr = task_corr\n",
    "    runner = ExpRunner(mmoe.exp, {'config': config}, repeat_num=8)\n",
    "    runner.run_mp()\n",
    "    series = process_result(runner)\n",
    "    moe_stats[task_corr] = series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance of MMoE, MoE, SharedBottom on synthetic data with different correlations\n",
    "\n",
    "we compare the validation loss of MMoE, MoE, SharedBottom  at different levels of task relatedness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 3, figsize=(14, 4), sharey=True)\n",
    "for i, task_corr in enumerate([0.5, 0.9, 1.0]):\n",
    "    ax[i].plot(shared_bottom_stats[task_corr], label='shared_bottom')\n",
    "    ax[i].plot(moe_stats[task_corr], label='moe')\n",
    "    ax[i].plot(mmoe_stats[task_corr], label='mmoe')\n",
    "    ax[i].set_title(f\"corr={task_corr}\")\n",
    "    ax[i].grid()\n",
    "\n",
    "ax[-1].legend()\n",
    "# ax[-1].set_ylim(0, 0.025)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
